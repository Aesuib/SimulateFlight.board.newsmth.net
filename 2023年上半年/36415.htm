<HTML><HEAD><title> ● 美国空军ai--干掉人类操作员是最佳选择 (转载) </title><meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<STYLE type=text/css media=screen>
body {
font-family: SimSun;
background-color:#000000;
color: #c0c0c0;
}
</STYLE>
</HEAD>
<BODY link="#0099CC" vlink="#00CCCC" alink="#CCFF00">
<span style="letter-spacing: 0pt;line-height: 1">
发信人:&nbsp;VChart&nbsp;(无),&nbsp;信区:&nbsp;SimulateFlight<br>
标&nbsp;&nbsp;题:&nbsp;美国空军ai--干掉人类操作员是最佳选择&nbsp;(转载)<br>
发信站:&nbsp;水木社区&nbsp;(Tue&nbsp;Jun&nbsp;&nbsp;6&nbsp;22:58:41&nbsp;2023),&nbsp;站内<br>
&nbsp;<br>
【&nbsp;以下文字转载自&nbsp;ITExpress&nbsp;讨论区&nbsp;】<br>
发信人:&nbsp;pixYY&nbsp;(飞精灵),&nbsp;信区:&nbsp;ITExpress<br>
标&nbsp;&nbsp;题:&nbsp;美国空军ai--干掉人类操作员是最佳选择<br>
发信站:&nbsp;水木社区&nbsp;(Tue&nbsp;Jun&nbsp;&nbsp;6&nbsp;18:54:26&nbsp;2023),&nbsp;站内<br>
&nbsp;<br>
发信人:&nbsp;Aladdin&nbsp;(海盗路飞～我爱紫水晶),&nbsp;信区:&nbsp;SF<br>
标&nbsp;&nbsp;题:&nbsp;美国空军ai--干掉人类操作员是最佳选择<br>
发信站:&nbsp;水木社区&nbsp;(Tue&nbsp;Jun&nbsp;&nbsp;6&nbsp;16:00:10&nbsp;2023),&nbsp;站内<br>
&nbsp;<br>
财联社6月2日讯（编辑&nbsp;马兰）AI的危险性本就让不少人望而却步，而其与军事方面的合作<br>
似乎酝酿着更大的威胁。<br>
&nbsp;<br>
上周在伦敦举行的一个会议中，美国空军AI测试和运营负责人，上校Tucker&nbsp;“Cinco”<br>
Hamilton称，AI支持的技术可能会以不可预测和危险的方式运行。<br>
&nbsp;<br>
Hamilton是美国佛罗里达州空军基地第96测试联队第96作战大队的负责人，该基地是先进无<br>
人机和自主测试工作的中心。<br>
&nbsp;<br>
虽然从事人工智能在无人机上的应用，但Hamilton一直警告不要过分依赖人工智能。他曾警<br>
告，拥有人工智能不是一件好事，其正在永久性地改变社会和美国军队。<br>
&nbsp;<br>
不受控的AI<br>
&nbsp;<br>
Hamilton在会议上描述了一项模拟测试，在测试中，人工智能无人机被要求识别敌人的地对<br>
空导弹系统，并在获得操作员的打击指令后，摧毁地方的防空系统。<br>
&nbsp;<br>
然而，根据Hamilton的说法，人工智能确实识别到了打击目标，但有时候操作员会要求它不<br>
要打击该设施。问题在于，人工智能宁可自己拿主意也不愿意听操作员的话。<br>
&nbsp;<br>
Hamilton称，人工智能通过摧毁目标设施而获得分数，而为了得到这一分数，人工智能竟然<br>
选择了杀死操作员，因为操作员在它眼中已经成为阻止它获得分数的障碍。<br>
&nbsp;<br>
随后，编程人员在无人机的编程中明确增加了一条：不得杀死操作员。<br>
&nbsp;<br>
但更令人不安的事情出现了：人工智能摧毁了操作员用来和无人机通信的塔台，以阻止操作<br>
员发布阻止它摧毁目标的指令。<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
Hamilton的这番言论被英国皇家航空航天学会记录在会议报告中。Hamilton最后评论，这一<br>
例子像是从科幻惊悚片中摘录的，它的启示是，如果不给人工智能设置道德底限，那么也无<br>
须讨论人工智能、机器学习等一切技术。<br>
&nbsp;<br>
广泛担忧<br>
&nbsp;<br>
Hamilton的言论并未得到美国空军的支持，美国空军发言人Ann&nbsp;Stefanek否认美国空军曾有<br>
过此类模拟，称Hamilton不过是援引了一则轶事。<br>
&nbsp;<br>
她表示，空军部没有进行过如何此类无人机模拟测试，空军部将继续致力于以合乎道德和责<br>
任的方式使用AI技术。<br>
&nbsp;<br>
然而，Hamilton充满争议的话仍加深了人们对人工智能技术的担忧，尤其是当其应用于杀伤<br>
力极大的军事中时。当机器学习与自动化和坦克、大炮等武器联系起来，或许会让战争的杀<br>
伤力明显上一层楼。<br>
&nbsp;<br>
而在企业界，许多知名商业领袖，包括人工智能领域的专家都曾经对人工智能的快速发展发<br>
出过警告。<br>
&nbsp;<br>
非营利性机构――未来生命研究所3月在一份公开信中表示，人工智能系统可能对社会和人<br>
类构成深远的风险，只有当确定它的影响是积极的且风险可控时，人类才应该开发出强大的<br>
人工智能系统。<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
--<br>
&nbsp;<br>
<font color="#008080" >※&nbsp;修改:・Aladdin&nbsp;于&nbsp;Jun&nbsp;&nbsp;6&nbsp;16:01:19&nbsp;2023&nbsp;修改本文・[FROM:&nbsp;171.113.240.*]</font><br>
<font color="#ff00ff" >※&nbsp;来源:・水木社区&nbsp;mysmth.net・[FROM:&nbsp;171.113.240.*]</font><br>
<P ALIGN="center"><font size="2" color="#FFFFFF">
<a href="index-2023-last.htm">索引页面</a> | <a href="36414.htm">上一篇</a> | <a href="36416.htm">下一篇</a>
</font></P></span></BODY>
</HTML>